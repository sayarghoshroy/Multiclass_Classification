{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "One_vs_K.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Multiclass_Classification/blob/master/One_vs_K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljb6j9TLmrvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using 10 one-v/s-K classifiers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnU-K642mrvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "def read_data(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    \n",
        "    num_points = len(lines)\n",
        "    dim_points = 28 * 28\n",
        "    data = np.empty((num_points, dim_points))\n",
        "    labels = np.empty(num_points)\n",
        "    \n",
        "    for ind, line in enumerate(lines):\n",
        "        num = line.split(',')\n",
        "        labels[ind] = int(num[0])\n",
        "        data[ind] = [ int(x) for x in num[1:] ]\n",
        "        \n",
        "    return (data, labels)\n",
        "\n",
        "train_data, train_labels = read_data(\"sample_train.csv\")\n",
        "test_data, test_labels = read_data(\"sample_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kim-vsPmrv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = np.shape(train_data)[0]\n",
        "pairs = []\n",
        "dividers = []\n",
        "#print(N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26f2x9m7mrwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for class_label in range(10):\n",
        "    datapoints = []\n",
        "    labels = []\n",
        "    for iterator in range(N):\n",
        "        if int(train_labels[iterator]) == class_label:\n",
        "            datapoints.append(train_data[iterator])\n",
        "            labels.append(1)\n",
        "        else:\n",
        "            datapoints.append(train_data[iterator])\n",
        "            labels.append(-1)\n",
        "    log_reg = LogisticRegression(solver = 'liblinear', max_iter = 10000)\n",
        "    clf = log_reg.fit(datapoints, labels)\n",
        "    dividers.append(clf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWp57l6wmrwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "T = len(test_data)\n",
        "count = 0\n",
        "\n",
        "for iterator in range(T):\n",
        "    probabilities = []\n",
        "    sum_p = 0\n",
        "    for class_label in range(10):\n",
        "        p = np.exp(np.dot(dividers[class_label].coef_[0], test_data[iterator]))\n",
        "        sum_p += p\n",
        "        probabilities.append(p)\n",
        "        \n",
        "    for change in range(10):\n",
        "        probabilities[change] /= sum_p\n",
        "        \n",
        "    prediction = np.argmax(probabilities)\n",
        "    predictions.append(prediction)\n",
        "    if int(prediction) == int(test_labels[iterator]):\n",
        "        count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiallK9dmrwp",
        "colab_type": "code",
        "colab": {},
        "outputId": "12d920bd-de24-464e-dad8-5f00f9fdd68f"
      },
      "source": [
        "accuracy = str((count / T) * 100)\n",
        "print(\"Accuracy using 10 one-v/s-K Classifiers =\", accuracy, \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using 10 one-v/s-K Classifiers = 77.3 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpFrU-dMmrw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}